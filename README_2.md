# Deep Learning Project: NLP_and_Deep_Learning_project

## Overview
Deep learning has emerged as a cornerstone of modern machine learning, providing effective solutions for complex problems across various domains. In this project, we focused on building and evaluating multiple deep-learning models to analyze the GoEmotions dataset, which was sourced from Kaggle. This dataset contains textual data annotated with multiple emotion labels, framing the task as a multi-class classification problem.
The primary objective of this project was to predict the emotional category associated with each text sample. The dataset's features are preprocessed textual data, numerically transformed through various methods, while the labels represent discrete emotion classes. To ensure reliable evaluation and model generalization, the dataset was split into training and test sets.
We began with a baseline model that consistently predicts the majority class to establish a simple reference point. Subsequently, a logistic regression model was implemented using TF-IDF (Term Frequency-Inverse Document Frequency) features to improve upon the baseline. Progressing further, a basic fully connected neural network was developed to explore the capabilities of deep learning. Finally, we incorporated an advanced architecture utilizing a recurrent neural network (RNN) to enhance performance further.
Each model was assessed using key metrics, including accuracy, precision, and recall. We iteratively refined the models, addressing challenges such as overfitting and underfitting, to optimize their performance.

## Table of Contents
- [Installation](#installation)
- [Requirements](#requirements)
- [Usage](#usage)
- [Training](#training)
- [Results](#results)

## Installation
To run this project on your local machine, follow these steps:

1. Clone this repository: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; https://github.com/ShahafSud/NLP_and_Deep_Learning_project.git
2. Make sure pip is updated pip install --upgrade pip (requirements.txt)
3. Run pip install -r requirements.txt
4. Run the script Data_visual_and_preparation.py - expect an error
5. Copy the path to dataset files and past in a local file named config.json as "Original_Dataset"
6. Run Data_visual_and_preparation.py again.
7. Now your datasets are saved, Train models as needed

## Requirements
"========================="

## Usage
"========================="

## Training
"========================="

## Results
"========================="
